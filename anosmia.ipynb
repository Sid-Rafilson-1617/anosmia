{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anosmia project analysis notebook\n",
    "\n",
    "This notebook contains the analysis of the data collected for the Anosmia project.\n",
    "\n",
    "\n",
    "***By: Sid Rafilson, Casey Lennon-Jones***\n",
    "\n",
    "***PI: Matt Smear***\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from scipy.interpolate import interp1d\n",
    "import os\n",
    "\n",
    "\n",
    "def load_sniff(sniff_file: str, num_samples: int = -1, start = 0, stop = 0, nchannels: int = 8, ch: int = 8) -> np.array:\n",
    "    '''\n",
    "    Load a specific channel from a binary sniff data file into a NumPy array.\n",
    "\n",
    "    This function reads a binary file containing multi-channel sniff data, processes it, \n",
    "    and extracts data from a specified channel.\n",
    "\n",
    "    Parameters:\n",
    "    sniff_file (str): The path to the binary file containing sniff data.\n",
    "    num_samples (int): The number of samples to read from the file.\n",
    "    nchannels (int, optional): The number of channels in the sniff data. Defaults to 8.\n",
    "    ch (int, optional): The channel number to extract. Defaults to 8. Channels are\n",
    "                        indexed starting from 1.\n",
    "\n",
    "    Returns:\n",
    "    np.array: A NumPy array containing the data from the specified channel.\n",
    "\n",
    "    Notes:\n",
    "    - The number of samples specified is dynamic for debugging but can easily fit the entire data set with num_samples = -1.\n",
    "    - Channel numbers start from 1. For instance, ch = 1 will extract the first channel.\n",
    "    '''\n",
    "    \n",
    "    # reading in binary data\n",
    "    num_samples = num_samples * nchannels\n",
    "    sniff_bin = np.fromfile(sniff_file, dtype=np.uint16, count=num_samples)\n",
    "\n",
    "    # ensuring equal samples from each channel\n",
    "    num_complete_sets = len(sniff_bin) // nchannels\n",
    "    sniff_bin = sniff_bin[:num_complete_sets * nchannels]\n",
    "\n",
    "    # reshaping data and extracting channel which corresponds to sniff voltage\n",
    "    sniff_bin = np.reshape(sniff_bin, (nchannels, -1), order='F')\n",
    "    ch_index = ch - 1\n",
    "    sniff = sniff_bin[ch_index, :]\n",
    "\n",
    "    # removing start seconds from beggining, and stop from end of signal; default is 0\n",
    "    start = start * 30000\n",
    "    stop = stop * 30000\n",
    "    if stop == 0:\n",
    "        sniff = sniff[start:]  \n",
    "    else:\n",
    "        sniff = sniff[start: -stop]\n",
    "\n",
    "    return sniff\n",
    "    \n",
    "\n",
    "\n",
    "def load_ephys(ephys_file: str, num_samples: int = -1, start = 0, stop = 0, nchannels: int = 16) -> np.array:\n",
    "    '''\n",
    "    Load and reshape binary electrophysiology data into a NumPy array.\n",
    "\n",
    "    This function is designed to read binary files containing electrophysiology \n",
    "    (ephys) data. It loads the specified number of samples from the file and \n",
    "    reshapes them into a 2D NumPy array, where each row represents a channel.\n",
    "\n",
    "    Parameters:\n",
    "    ephys_file (str): Path to the binary file containing electrophysiology data.\n",
    "    num_samples (int): Number of samples to read from the file.\n",
    "    nchannels (int, optional): Number of channels in the ephys data. Defaults to 16.\n",
    "\n",
    "    Returns:\n",
    "    np.array: A 2D NumPy array of the electrophysiology data, reshaped into\n",
    "              (nchannels, number_of_samples_per_channel).\n",
    "    '''\n",
    "  \n",
    "    # reading in binary data\n",
    "    num_samples = num_samples * nchannels\n",
    "    ephys_bin = np.fromfile(ephys_file, dtype=np.uint32, count = num_samples)\n",
    "    \n",
    "    # ensuring equal samples from each channel\n",
    "    num_complete_sets = len(ephys_bin) // nchannels\n",
    "    ephys_bin = ephys_bin[:num_complete_sets * nchannels]\n",
    "\n",
    "    # reshape 1d array into nchannels x num_samples NumPy array\n",
    "    ephys_data = np.reshape(ephys_bin, (nchannels, -1), order='F')\n",
    "\n",
    "    # removing start seconds from beggining, and stop from end of signal; default is 0\n",
    "    start = start * 30000\n",
    "    stop = stop * 30000\n",
    "\n",
    "    if stop == 0:\n",
    "        ephys = ephys_data[:, start:]\n",
    "    else:\n",
    "        ephys = ephys_data[:, start: -stop]\n",
    "\n",
    "    return ephys\n",
    "\n",
    "\n",
    "\n",
    "def resample_sniff(sniff: np.array, original_rate = 30000, target_rate = 1000) -> np.array:\n",
    "    '''\n",
    "    Resample a sniff signal from an original rate to a target rate.\n",
    "\n",
    "    This function applies a decimation process to a sniff signal, which is useful in \n",
    "    situations where lower sampling rates are sufficient or desired for analysis. The \n",
    "    decimation is performed using a Finite Impulse Response (FIR) filter with a Hamming \n",
    "    window to reduce aliasing effects.\n",
    "\n",
    "    Parameters:\n",
    "    sniff (np.array): The sniff signal to be resampled, represented as a NumPy array.\n",
    "    original_rate (int, optional): The original sampling rate of the signal in Hz. Defaults to 30000 Hz.\n",
    "    target_rate (int, optional): The desired sampling rate of the signal in Hz. Defaults to 1000 Hz.\n",
    "\n",
    "    Returns:\n",
    "    np.array: The resampled sniff signal.\n",
    "    '''\n",
    "\n",
    "    # calculating resample factor\n",
    "    resample_factor = original_rate // target_rate\n",
    "\n",
    "    # calculating new length of resampled signal\n",
    "    if 0 != sniff.shape[0] % resample_factor:\n",
    "        sniff = sniff[:-(sniff.shape[0] % resample_factor)]\n",
    "\n",
    "    # calculating new length of resampled signal\n",
    "    print(f'Resampling from length {sniff.shape[0]}')\n",
    "    new_length = sniff.shape[0]//resample_factor\n",
    "\n",
    "    # applying decimation to the signal\n",
    "    resampled_sniff = np.zeros(new_length)\n",
    "    resampled_sniff = signal.decimate(sniff, resample_factor, ftype = 'fir')\n",
    "\n",
    "    return resampled_sniff\n",
    "    \n",
    "\n",
    "\n",
    "def resample_ephys(ephys: np.array, nchannels = 16, original_rate = 30000, target_rate = 1000) -> np.array:\n",
    "    '''\n",
    "    Resample multi-channel electrophysiology (ephys) data from an original sampling rate to a target rate.\n",
    "\n",
    "    This function applies a decimation process to each channel of a multi-channel ephys signal. \n",
    "    It uses a 30-point Finite Impulse Response (FIR) filter with a Hamming window to mitigate \n",
    "    aliasing effects during resampling.\n",
    "\n",
    "    Parameters:\n",
    "    ephys (np.array): A 2D NumPy array representing the ephys data, with shape (nchannels, number_of_samples).\n",
    "    nchannels (int, optional): Number of channels in the ephys data. Defaults to 16.\n",
    "    original_rate (int, optional): Original sampling rate of the ephys data in Hz. Defaults to 30000 Hz.\n",
    "    target_rate (int, optional): Target sampling rate in Hz. Defaults to 1000 Hz.\n",
    "\n",
    "    Returns:\n",
    "    np.array: A 2D NumPy array of the resampled ephys data, with the same number of channels \n",
    "              and a reduced number of samples per channel.\n",
    "    '''\n",
    "\n",
    "    # calculating resample factor\n",
    "    resample_factor = original_rate // target_rate\n",
    "\n",
    "    # removing samples from the end of the signal if the length is not divisible by the resample factor\n",
    "    if 0 != ephys.shape[1] % resample_factor:\n",
    "        ephys = ephys[:, :-(ephys.shape[1] % resample_factor)]\n",
    "\n",
    "    # calculating new length of resampled signal\n",
    "    print(f'Resampling Ephys from length {ephys.shape[1]}')\n",
    "    new_length = ephys.shape[1]//resample_factor\n",
    "\n",
    "    # applying decimation to the signal\n",
    "    resampled_ephys = np.zeros((nchannels, new_length))\n",
    "    for ch in range(nchannels):\n",
    "        resampled_ephys[ch, :] = signal.decimate(ephys[ch,:], resample_factor, ftype = 'fir')\n",
    "\n",
    "    return resampled_ephys\n",
    "\n",
    "\n",
    "\n",
    "def find_inhales(data: np.array, window_length = 51, polyorder = 5, min_peak_prominance = 75) -> np.array:\n",
    "    '''\n",
    "    Smooth a  signal using the Savitzky-Golay method and locate inhalation times using peak finding.\n",
    "\n",
    "    This function first applies a Savitzky-Golay filter to smooth the input signal. \n",
    "    It then uses a peak finding algorithm to identify the times of inhalations, which are \n",
    "    indicated by prominent peaks in the smoothed signal. Optionally, the function can also \n",
    "    plot the original and smoothed signals along with the identified peaks.\n",
    "\n",
    "    Parameters:\n",
    "    data (np.array): The signal to be processed, represented as a NumPy array.\n",
    "    window_length (int, optional): The length of the filter window. Defaults to 101.\n",
    "    polyorder (int, optional): The order of the polynomial used to fit the samples. Defaults to 9.\n",
    "    min_peak_prominance (int, optional): The minimum prominence of a peak to be considered \n",
    "                                         an inhalation. Defaults to 50.\n",
    "    show (bool, optional): If True, display a plot of the original and smoothed signals with peaks. \n",
    "                           Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing two elements:\n",
    "           - locs (np.array): An array of indices where inhalation peaks are located.\n",
    "           - smoothed_sniff (np.array): The smoothed sniff signal.\n",
    "    '''\n",
    "\n",
    "    smoothed_data = signal.savgol_filter(data, window_length, polyorder)\n",
    "    locs, properties = signal.find_peaks(smoothed_data, height = (None, None), prominence = min_peak_prominance)\n",
    "    \n",
    "\n",
    "    return locs, smoothed_data, properties\n",
    "\n",
    "\n",
    "\n",
    "def sniff_lock_lfp(locs: np.array, ephys: np.array, window_size = 1000, nsniffs = 512, beg = 3000, method = 'zscore') -> np.array:\n",
    "    '''\n",
    "    Aligns local field potential (LFP) signals with sniff inhalation times and constructs a 3D array of z-scored LFP activity.\n",
    "\n",
    "    This function identifies segments of LFP signals corresponding to inhalation times (specified by 'locs') and \n",
    "    standardizes these segments across channels. The output is a 3D array where each 'slice' corresponds to the LFP \n",
    "    activity surrounding a single sniff event, with data from all channels.\n",
    "\n",
    "    Parameters:\n",
    "    locs (np.array): Array of sniff inhalation times (indices).\n",
    "    ephys (np.array): 2D array of electrophysiological data with shape (nchannels, number_of_samples).\n",
    "    nchannels (int, optional): Number of channels in the ephys data. Defaults to 16.\n",
    "    window_size (int, optional): The size of the window around each sniff event to consider for LFP activity. Defaults to 1000.\n",
    "    nsniffs (int, optional): Number of sniff events to process. Defaults to 512.\n",
    "    beg (int, optional): Starting index to begin looking for sniff events. Defaults to 3000.\n",
    "\n",
    "    Returns:\n",
    "    sniff_activity (np.array): A 3D NumPy array with shape (nsniffs, window_size, nchannels). Each 'slice' of this array \n",
    "              represents the z-scored LFP activity around a single sniff event for all channels.\n",
    "    loc_set (np.array): An array of indices where inhalation peaks are located.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the 'locs' array does not contain enough data after the specified 'beg' index for the required number of sniffs.\n",
    "    '''\n",
    "\n",
    "\n",
    "    # finding number of channels\n",
    "    nchannels = ephys.shape[0]\n",
    "\n",
    "\n",
    "    # finding the set of inhalation times to use\n",
    "    if nsniffs == 'all':\n",
    "        loc_set = locs[5:-5]\n",
    "        nsniffs = len(loc_set)\n",
    "    elif isinstance(nsniffs, int):\n",
    "        first_loc = np.argmax(locs >= beg)\n",
    "        loc_set = locs[first_loc: first_loc + nsniffs]\n",
    "    else:\n",
    "        raise ValueError(\"nsniffs must be either 'all' or an integer.\")\n",
    "\n",
    "    # checking if locs array has enough data for the specified range\n",
    "    if isinstance(nsniffs, int):\n",
    "        if len(loc_set) < nsniffs:\n",
    "            raise ValueError(\"locs array does not have enough data for the specified range.\")\n",
    "        \n",
    "    # propogates an nx2 array containing times half the window size in both directions from inhalation times\n",
    "    windows = np.zeros((nsniffs, 2), dtype=int)\n",
    "    for ii in range(nsniffs):\n",
    "        win_beg = loc_set[ii] - round(window_size/2)\n",
    "        win_end = loc_set[ii] + round(window_size/2)\n",
    "        windows[ii] = [win_beg, win_end]\n",
    "\n",
    "    if method == 'zscore':\n",
    "        # finds and saves zscored ephys data from each channel for each inhalaion locked time window\n",
    "        sniff_activity = np.zeros((nchannels, nsniffs, window_size))\n",
    "        for ii in range(nsniffs):\n",
    "            for ch in range(nchannels):\n",
    "                win_beg, win_end = windows[ii]\n",
    "                data = ephys[ch, win_beg:win_end]\n",
    "                data_mean = np.mean(data)\n",
    "                data_std = np.std(data)\n",
    "                zscore_data = (data - data_mean) / data_std\n",
    "                if len(data) < window_size:\n",
    "                    data = np.pad(data, (0, window_size - len(data)), mode = 'constant', constant_values = 0)\n",
    "                    print('!!! padding !!!')\n",
    "                sniff_activity[ch,ii,:] = zscore_data\n",
    "\n",
    "    elif method == 'none':\n",
    "        sniff_activity = np.zeros((nchannels, nsniffs, window_size))\n",
    "        for ii in range(nsniffs):\n",
    "            for ch in range(nchannels):\n",
    "                win_beg, win_end = windows[ii]\n",
    "                data = ephys[ch, win_beg:win_end]\n",
    "                if len(data) < window_size:\n",
    "                    data = np.pad(data, (0, window_size - len(data)), mode = 'constant', constant_values = 0)\n",
    "                    print('!!! padding !!!')\n",
    "                sniff_activity[ch,ii,:] = data\n",
    "\n",
    "    return sniff_activity, loc_set\n",
    "\n",
    "\n",
    "\n",
    "def sort_lfp(sniff_activity, locs):\n",
    "    '''sorts the sniff locked lfp trace by sniff frequency'''\n",
    "\n",
    "    # finding data shape\n",
    "    nchannels = sniff_activity.shape[0]\n",
    "    nsniffs = sniff_activity.shape[1]\n",
    "    window_size = sniff_activity.shape[2]\n",
    "    \n",
    "    sorted_activity = np.zeros((nchannels, nsniffs-1, window_size))\n",
    "    \n",
    "    # finding sniff frequencies by inhalation time differences (we lose the last sniff)\n",
    "    freqs = np.diff(locs)\n",
    "\n",
    "    # sorting the ephys data and frequency values according to these times\n",
    "    sort_indices = np.argsort(freqs)\n",
    "    sorted_activity[:, :, :] = sniff_activity[:, sort_indices, :]\n",
    "    sorted_freqs = freqs[sort_indices]\n",
    "    sorted_freqs = 1 / (sorted_freqs / 1000)\n",
    "\n",
    "    return sorted_activity, sorted_freqs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = r\"\\\\F-MOVING-DATA\\EphysData\\SidData\\Anosmia Ephys Data\"\n",
    "mouse = '5001E'\n",
    "session = \"PRE1\"\n",
    "\n",
    "nch = 16\n",
    "\n",
    "\n",
    "# finding mouse directories\n",
    "mouse_dirs = os.listdir(data_dir)\n",
    "print(f\"Mouse directories in the main data directory: {mouse_dirs}\")\n",
    "\n",
    "\n",
    "# finding sessions for a specific mouse\n",
    "sessions = os.listdir(os.path.join(data_dir, mouse))\n",
    "print(f\"Sessions for mouse {mouse}: {sessions}\")\n",
    "\n",
    "\n",
    "# loading ephys and sniff data files\n",
    "files = os.listdir(os.path.join(data_dir, mouse, session))\n",
    "ephys_file = [file for file in files if file.endswith('Ephys.bin')][0]\n",
    "ephys_file = os.path.join(data_dir, mouse, session, ephys_file)\n",
    "sniff_file = [file for file in files if file.endswith('ADC.bin')][0]\n",
    "sniff_file = os.path.join(data_dir, mouse, session, sniff_file)\n",
    "print(f\"Ephys file: {ephys_file}\\nSniff file: {sniff_file}\\n\\n\")\n",
    "\n",
    "\n",
    "# loading raw sniff and ephys data\n",
    "sniff = load_sniff(sniff_file)\n",
    "ephys = load_ephys(ephys_file, nchannels = nch)\n",
    "print(f'Data Loaded\\n---------------------------------------\\nlength of sniff signal: {sniff.shape[0]}\\nShape of ephys signal: {ephys.shape}\\n')\n",
    "\n",
    "\n",
    "# filtering and resampling ephys to get LFP\n",
    "sos = signal.butter(10, 200, 'low', fs = 30_000, output = 'sos')\n",
    "lfp = resample_ephys(signal.sosfiltfilt(sos, ephys, axis = 1), nchannels = nch, original_rate = 30_000, target_rate = 1_000)\n",
    "print(f'\\nLFP filtered and resampled\\n-------------------------\\nShape of LFP signal: {lfp.shape}\\n')\n",
    "\n",
    "\n",
    "# resampling sniff signal to match LFP\n",
    "sniff_resampled = resample_sniff(sniff, original_rate = 30_000, target_rate = 1_000)\n",
    "print(f'Sniff resampled\\n-----------------------------------\\nLength of resampled sniff signal: {sniff_resampled.shape[0]}\\n')\n",
    "\n",
    "\n",
    "# filtering ephys to get spikes\n",
    "sos = signal.butter(10, 1_000, 'high', fs = 30_000, output = 'sos')\n",
    "spikes = signal.sosfiltfilt(sos, ephys, axis = 1)\n",
    "print(f'Spikes filtered\\n-----------------------------------\\nShape of spikes signal: {spikes.shape}\\n')\n",
    "\n",
    "\n",
    "# time vectors\n",
    "time_lfp = np.arange(0, sniff_resampled.shape[0], 1) / 1_000\n",
    "time_spikes = np.arange(0, spikes.shape[1], 1) / 30_000\n",
    "print(f'\\nTime vectors created\\n-----------------------------------\\nlength of time vector for LFP: {time_lfp.shape[0]}\\nlength of time vector for spikes: {time_spikes.shape[0]}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = {'theta': (0.5, 24), 'beta': (24, 40), 'gamma': (65, 85)}\n",
    "\n",
    "for key, value in tqdm(filters.items(), desc='Filtering LFP signals'):\n",
    "    sos = signal.butter(10, value, 'band', fs=1000, output='sos')\n",
    "    filtered = signal.sosfiltfilt(sos, lfp, axis=1)\n",
    "    globals()[key] = filtered\n",
    "    del sos\n",
    "\n",
    "print(f'\\nLFP signals filtered\\n-----------------------------------\\nShape of LFP signal: {lfp.shape}\\n')\n",
    "gamma_envelope = np.abs(signal.hilbert(gamma, axis=1))\n",
    "print(f'Gamma envelope calculated\\n-----------------------------------\\nlength of gamma envelope signal: {gamma_envelope.shape[1]}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the LFPs with sniff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(r\"E:\\anosmia\\figs\", mouse, session)\n",
    "\n",
    "lfps = {'raw': lfp, 'theta': theta, 'beta': beta, 'gamma': gamma, 'gamma_envelope': gamma_envelope}\n",
    "\n",
    "fig_path = os.path.join(save_dir, 'sniff_lfp')\n",
    "if not os.path.exists(fig_path):\n",
    "    os.makedirs(fig_path)\n",
    "\n",
    "\n",
    "\n",
    "for key, value in tqdm(lfps.items(), desc='Plotting LFPs'):\n",
    "\n",
    "    start = 0\n",
    "    end = 3_000\n",
    "\n",
    "    save_path = os.path.join(fig_path, key)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "\n",
    "\n",
    "    for j in range(10):\n",
    "        \n",
    "        fig, axs = plt.subplots(nch + 1, 1, figsize=(17, 30), sharex=True)\n",
    "        sns.despine()\n",
    "        axs[0].plot(time_lfp[start:end], sniff_resampled[start:end], color='black')\n",
    "        axs[0].set_title('Sniff')\n",
    "        axs[0].set_ylabel('Voltage (AU)')\n",
    "        axs[0].set_yticks([])\n",
    "        for i in range(nch):\n",
    "            mi = mutual_info_regression(time_lfp[start:end, None], value[i, start:end])\n",
    "            axs[i+1].plot(time_lfp[start:end], value[i, start:end], color='black')\n",
    "            axs[i+1].set_title(f'Channel {i+1}: MI = {mi[0]:.2f} ')\n",
    "            axs[i+1].set_ylabel('Voltage (AU)')\n",
    "            axs[i+1].set_yticks([])\n",
    "        axs[-1].set_xlabel('Time (s)')\n",
    "        fig.suptitle(f'{key} LFPs')\n",
    "        fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        fig.savefig(os.path.join(save_path, f'{key}_lfp_{j}.png'))\n",
    "        plt.close(fig)\n",
    "\n",
    "        start += 3_000\n",
    "        end += 3_000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Spikes with sniff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_path = os.path.join(save_dir, 'sniff_spikes')\n",
    "if not os.path.exists(fig_path):\n",
    "    os.makedirs(fig_path)\n",
    "\n",
    "start = 0\n",
    "end = start + 90_000\n",
    "\n",
    "for j in tqdm(range(10), desc='Plotting Spikes'):\n",
    "\n",
    "    fig, axs = plt.subplots(nch + 1, 1, figsize=(17, 30), sharex=True)\n",
    "    sns.despine()\n",
    "    axs[0].plot(time_spikes[start:end], sniff[start:end], color = 'black', linewidth=0.5)\n",
    "    axs[0].set_title('Sniff Data')\n",
    "    axs[0].set_ylabel('Voltage (mV)')\n",
    "    for i in range(1, nch):\n",
    "        mi = mutual_info_regression(time_spikes[start:end, None], spikes[i-1, start:end])\n",
    "        axs[i].plot(time_spikes[start:end], spikes[i-1, start:end], color ='black', linewidth=0.1)\n",
    "        axs[i].set_title(f'Channel {i}: MI = {mi[0]:.2f}')\n",
    "        axs[i].set_ylabel('Voltage (mV)')\n",
    "    axs[nch].set_xlabel('Time (s)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{fig_path}\\\\sniff_spikes{j}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    start += 90_000\n",
    "    end += 90_000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding inhalation times and plotting the sniff frequency histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs, _, _ = find_inhales(sniff_resampled)\n",
    "freqs = 1000 / np.diff(locs)\n",
    "freqs = freqs[(freqs < 16) & (freqs > 0.5)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(freqs, bins = 50, kde = True)\n",
    "plt.title('Sniff Frequency Distribution')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(f'{save_dir}\\\\sniff_freqs.png', dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building sniff aligned LFP rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig_path = os.path.join(save_dir, 'sniff rasters')\n",
    "if not os.path.exists(fig_path):\n",
    "    os.makedirs(fig_path)\n",
    "\n",
    "\n",
    "lfps = {'raw': lfp, 'theta': theta, 'beta': beta, 'gamma': gamma, 'gamma_envelope': gamma_envelope, 'spikes': spikes}\n",
    "\n",
    "for key, value in tqdm(lfps.items(), desc='Plotting LFPs'):\n",
    "\n",
    "    raster_path = os.path.join(fig_path, key)\n",
    "    if not os.path.exists(raster_path):\n",
    "        os.makedirs(raster_path)\n",
    "\n",
    "    if key == 'spikes':\n",
    "        activity, locs = sniff_lock_lfp(locs * 30, value)\n",
    "    else:\n",
    "        activity, locs = sniff_lock_lfp(locs, value)\n",
    "        \n",
    "    sorted_activity, sorted_freqs = sort_lfp(activity, locs)\n",
    "\n",
    "    vmax = np.percentile(sorted_activity, 95.5)\n",
    "\n",
    "    for i in range(nch):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(sorted_activity[i, :, :], cmap='seismic', robust=True, vmax=vmax, vmin=-vmax)\n",
    "        plt.title(f'Channel {i+1}')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.savefig(f'{raster_path}\\\\channel_{i+1}.png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing spike data and looking for threshold crossings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing spiking data\n",
    "normalized_spiking = stats.zscore(spikes, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "threshold = 5\n",
    "crossings = np.zeros(normalized_spiking.shape)\n",
    "\n",
    "# looping through each channel and finding threshold crossings (spike times)\n",
    "for i in tqdm(range(nch), desc='Finding Spikes'):\n",
    "    data = normalized_spiking[i, :]\n",
    "    current_crossings = np.where(np.diff(data > threshold) == 1)\n",
    "    crossings[i, current_crossings] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig_path_waves = os.path.join(save_dir, 'spike_waves')\n",
    "fig_path_heatmaps = os.path.join(save_dir, 'spike_heatmaps')\n",
    "\n",
    "if not os.path.exists(fig_path_waves):\n",
    "    os.makedirs(fig_path_waves)\n",
    "if not os.path.exists(fig_path_heatmaps):\n",
    "    os.makedirs(fig_path_heatmaps)\n",
    "\n",
    "waves = [[] for _ in range(nch)]\n",
    "\n",
    "# Collect waveforms and plot line plots\n",
    "for ch in tqdm(range(nch)):\n",
    "    spike_times = np.where(crossings[ch, :] == 1)[0]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if len(spike_times) > 0:\n",
    "        lw = 0.1 if len(spike_times) > 100 else 0.5\n",
    "        for spike_time in spike_times:\n",
    "            start = spike_time - 15\n",
    "            end = spike_time + 15\n",
    "            if start >= 0 and end < normalized_spiking.shape[1]:  # Check bounds\n",
    "                current_spike = normalized_spiking[ch, start:end]\n",
    "                plt.plot(current_spike, linewidth=lw, alpha=0.2)\n",
    "                if current_spike.shape[0] == 30:\n",
    "                    waves[ch].append(current_spike)\n",
    "\n",
    "        plt.xticks([0, 5, 10, 15, 20, 25, 30], ['-1', '-2/3', '-1/3', '0', '1/3', '2/3', '1'])\n",
    "        plt.title(f'Channel {ch+1} Spike Waves')\n",
    "        plt.xlabel('Time lag (ms)')\n",
    "        plt.ylabel('Voltage (z-score)')\n",
    "        sns.despine()\n",
    "        plt.savefig(f'{fig_path_waves}/spike_waves_{ch+1}.png', dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the time resolution of the spike waves using interpolation\n",
    "interpolated_waves = [[] for _ in range(nch)]\n",
    "for ch in tqdm(range(nch)):\n",
    "    for wave in waves[ch]:\n",
    "        x = np.arange(0, 30)\n",
    "        f = interp1d(x, wave, kind='cubic')\n",
    "        x_new = np.linspace(0, 29, 1000)  # Increase the resolution\n",
    "        y_new = f(x_new)\n",
    "        interpolated_waves[ch].append(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create and plot density heatmaps\n",
    "for ch in range(nch):\n",
    "    current_data = np.array(interpolated_waves[ch])\n",
    "    tqdm.write(f'Channel {ch+1} has {current_data.shape} shape')\n",
    "    if current_data.shape[0] == 0:\n",
    "        continue\n",
    "\n",
    "    # Create a 2D histogram of the spike data\n",
    "    time_bins = 1000  # Number of time bins for increased resolution\n",
    "    voltage_bins = 100  # Number of voltage bins\n",
    "    hist_data, xedges, yedges = np.histogram2d(\n",
    "        np.tile(np.arange(current_data.shape[1]), current_data.shape[0]),\n",
    "        current_data.ravel(),\n",
    "        bins=[time_bins, voltage_bins],\n",
    "        range=[[0, 1000], [current_data.min(), current_data.max()]]\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(hist_data.T, cmap='seismic', robust=True, cbar=True)\n",
    "    plt.xticks(ticks=np.linspace(0, 1000, 7), labels=['-1', '-2/3', '-1/3', '0', '1/3', '2/3', '1'])\n",
    "    plt.yticks(ticks=np.linspace(0, voltage_bins, 11), labels=np.round(np.linspace(current_data.min(), current_data.max(), 11), 2))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title(f'Channel {ch+1} Spike Density Heatmap')\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('Voltage (z-score)')\n",
    "    plt.savefig(f'{fig_path_heatmaps}/spike_heatmap_{ch+1}.png', dpi=300)\n",
    "    plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
